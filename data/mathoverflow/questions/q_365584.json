{
  "id": "q_365584",
  "mathoverflow_id": 365584,
  "url": "https://mathoverflow.net/questions/365584/is-there-a-difference-between-using-nats-and-bits-to-express-entropy",
  "title": "nt.number theory - Is there a difference between using nats and bits to express entropy?",
  "body": "It seems to me like questions involving decimal vs binary representations of some number are not particularly interesting: for instance $\\pi$ or $\\sqrt{2}$ are conjectured to be normal in every base, and as far as I know this is open for any particular base. On the other hand, in calculating entropy there is again a choice of basis. Further, this gives us certain 'distinguished' real numbers: e.g. the entropy of the Gauss-Kuzmin distribution is $3.432527514776...$ bits, while it is $2.379246769061...$ nats. Are the properties of these digit strings of the same number 'similar' in any way, or is one 'nicer' in some sense? nt.number-theory it.information-theory entropy Share Cite Improve this question Follow asked Jul 14, 2020 at 3:24 Ryan 226 1 1 gold badge 6 6 silver badges 10 10 bronze badges $\\endgroup$ 3 $\\begingroup$ this is a bit vague. does one of those two numbers you gave look nicer to you in some sense? is that why you asked? $\\endgroup$ kodlu –  kodlu 2020-07-14 07:04:06 +00:00 Commented Jul 14, 2020 at 7:04 $\\begingroup$ I also don't understand the question. $\\endgroup$ Kurisuto Asutora –  Kurisuto Asutora 2020-07-14 07:41:48 +00:00 Commented Jul 14, 2020 at 7:41 1 $\\begingroup$ I understand the question as follows: some properties of numbers (such as normality) are basis-independent, others are basis-dependent (such as entropy). In the latter case, has the mathematical community come up with arguments in favor of some preferred basis in which to work? $\\endgroup$ Alex M. –  Alex M. 2020-07-16 05:38:07 +00:00 Commented Jul 16, 2020 at 5:38 Add a comment  |  0 Sorted by: Reset to default Highest score (default) Date modified (newest first) Date created (oldest first) You must log in to answer this question. Start asking to get answers Find the answer to your question by asking. Ask question Explore related questions nt.number-theory it.information-theory entropy See similar questions with these tags. The Overflow Blog Now everyone can chat on Stack Overflow Featured on Meta A proposal for bringing back Community Promotion & Open Source Ads Community Asks Sprint Announcement – January 2026: Custom site-specific badges! Citation Helper v2 - User Script edition! Related 15 How Does Random Noise Typically Look? 29 Can a string's sophistication be defined in an unsophisticated way? 4 Fastest Digit Extraction for Any Irrational Number 10 Are there numbers whose binary and ternary representations simultaneously have few digit transitions? How frequent are those numbers? 23 information-theoretic derivation of the prime number theorem 2 Difference between Shannon entropy and min-entropy 20 Intuitive/combinatorial proof for Boppana entropy inequality $H(x^2)\\ge\\phi xH(x)$, i.e. $\\binom{\\phi p n}{\\phi p^2 n} \\leq \\binom{n}{p^2n}$ $(function() { $(\".js-gps-related-questions .spacer\").on(\"click\", function () { fireRelatedEvent($(this).index() + 1, $(this).data('question-id')); }); function fireRelatedEvent(position, questionId) { StackExchange.using(\"gps\", function() { StackExchange.gps.track('related_questions.click', { position: position, originQuestionId: 365584, relatedQuestionId: +questionId, location: 'sidebar', source: 'Baseline' }); }); } }); Question feed",
  "tags": "nt.number-theory,it.information-theory,entropy,nt.number-theory,it.information-theory,entropy",
  "scraped_at": "2026-01-14T04:22:27.031085",
  "answer": ""
}